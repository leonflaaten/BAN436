{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 04-Data wrangling\n",
    "\n",
    "This notebook gives an introduction to the most common operations for transforming and cleaning data in `pandas`."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Data wrangling is the process of transforming data to a format that is suitable for answering an analytical question. This involves e.g. creating new variables, filtering rows, combining data sets etc."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Data transformation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "grade_dict = {'Name'  : ['Ole', 'Jenny', 'Chang', 'Jonas'],\n",
    "              'Score' : [65.0, 58.0, 79.0, 95.0],\n",
    "              'Pass'  : ['yes', 'no', 'yes', 'yes']}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df = pd.DataFrame(grade_dict)\n",
    "\n",
    "df"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Create new columns**"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We have already seen how we can change an existing column in a `DataFrame`, e.g. use `astype` to change the `dtype` of a column."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df['Score'] = df['Score'].astype(int)\n",
    "\n",
    "df"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We create a new column in an existing `DataFrame` by assigning a list of values to a new column name using the `=` operator."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df['Age'] = [19, 18, 20, 22]\n",
    "\n",
    "df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df['City'] = ['Bergen', 'Oslo', 'Trondheim', 'Bergen']\n",
    "\n",
    "df"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<div class=\"alert alert-info\">\n",
    "<h3> Your turn</h3>\n",
    "    <p> Import the file <code>temperatures.xlsx</code> that you created on Day 2, and store it as <code>temp_df</code> (remember to add the excel file to the <code>Data</code> folder).\n",
    "        \n",
    "Add a column that records the temperature in your home town (or any other city that you like) for the last seven days.\n",
    "\n",
    "</div>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Solution**\n",
    "\n",
    "<details>\n",
    "    \n",
    "<summary> Click to expand!</summary>\n",
    "<p> \n",
    "\n",
    "```c#\n",
    "# import file\n",
    "temps_df = pd.read_excel('data/temperatures.xlsx')\n",
    "    \n",
    "# add column for home town\n",
    "temp_df['mo i rana'] = [-7, -11, -12, -13, -6, 1, 2]\n",
    "```\n",
    "\n",
    "</p>\n",
    "</details> "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Notice that we can create a new column based on the values in an existing column."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df['Score_share'] = df['Score'] / 100\n",
    "\n",
    "df"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<div class=\"alert alert-info\">\n",
    "<h3> Your turn</h3>\n",
    "    <p> Import <code>mpg.xlsx</code> as <code>mpg_df</code>. The column <code>model_year</code> ranges from 1970 to 1984, but it contains only the last two digits of the year. Change the column so that it also contains the two first digits. E.g. '74' should be '1974'.\n",
    "\n",
    "</div>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Solution**\n",
    "\n",
    "<details>\n",
    "    \n",
    "<summary> Click to expand!</summary>\n",
    "<p> \n",
    "\n",
    "```c#\n",
    "    \n",
    "# import df\n",
    "mpg_df = pd.read_excel('data/mpg.xlsx')\n",
    "    \n",
    "# Alternative 1:\n",
    "# convert to string and then add the string \"19\" to the beginning of each year\n",
    "\n",
    "mpg_df['model_year'] = mpg_df['model_year'].astype('str')\n",
    "\n",
    "mpg_df['model_year'] = '19' + mpg_df['model_year']\n",
    " \n",
    "    \n",
    "# Alternative 2\n",
    "# keep as integer and simply add 1900 to each year\n",
    "\n",
    "mpg_df['model_year'] = mpg_df['model_year'] + 1900\n",
    "\n",
    "```\n",
    "\n",
    "</p>\n",
    "</details> "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Drop rows and columns**"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We drop rows and columns by using the function `drop`. \n",
    "\n",
    "`drop` has two mandatory parameters: the row/column labels that we want to drop, and `axis` which tells the function to drop either rows or columns.\n",
    "\n",
    "\n",
    "- `axis = 0` will drops rows\n",
    "\n",
    "- `axis = 1` will drops columns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df.drop(0, axis = 0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df.drop('Score_share', axis = 1)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We can store the modified `DataFrame` in a new variable."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df1 = df.drop('Score_share', axis = 1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df1"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We can drop several columns by passing a *list* of column names to the the `drop` function. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df.drop(['Score_share', 'Pass'], axis = 1)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Notice that many functions in `pandas` has an optional parameter called `inplace`. \n",
    "\n",
    "Setting `inplace = True` will transform the original `DataFrame`, so that we do not have to store the transformed `DataFrame` in a new variable."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df.drop(['Score_share', 'Pass'], axis = 1, inplace = True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<div class=\"alert alert-info\">\n",
    "<h3> Your turn</h3>\n",
    "    <p> Drop the columns <code>oslo</code> and <code>trondheim</code> from <code>temp_df</code>.\n",
    "</div>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Solution**\n",
    "\n",
    "<details>\n",
    "    \n",
    "<summary> Click to expand!</summary>\n",
    "<p> \n",
    "\n",
    "```c#\n",
    "temp_df.drop(['oslo', 'trondheim'], axis = 1, inplace = True)\n",
    "```\n",
    "\n",
    "</p>\n",
    "</details> "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Sometimes we want to drop rows/columns with missing data from our `DataFrame`. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "titanic = pd.read_csv('data/titanic.csv')\n",
    "\n",
    "titanic.isna().sum()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "`dropna` drops rows/columns with missing observations from a `DataFrame`. The specify the `axis` parameter in order to determine whether we want to drop rows or columns:\n",
    "- `axis = 0` will drop all rows with `Nan`\n",
    "- `axis = 1` will drop all columns with `NaN`"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "drop_nan_rows = titanic.dropna(axis = 0)\n",
    "\n",
    "drop_nan_rows"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "drop_nan_cols = titanic.dropna(axis = 1)\n",
    "\n",
    "drop_nan_cols"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Notice that `dropna` also has the parameter `inplace`. Setting `inplace = True` will drop the rows/columns with missing observations from the original `DataFrame`."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<div class=\"alert alert-info\">\n",
    "<h3> Your turn</h3>\n",
    "    <p> Drop the rows with missing observations in <code>mpg_df</code>. How many rows are left in <code>mpg_df</code>?\n",
    "</div>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Solution**\n",
    "\n",
    "<details>\n",
    "    \n",
    "<summary> Click to expand!</summary>\n",
    "<p> \n",
    "\n",
    "```c#\n",
    "# drop rows with missing from original dataframe\n",
    "mpg_df.dropna(axis = 0, inplace = True)\n",
    "\n",
    "# number of observations left\n",
    "print(len(mpg_df))\n",
    "```\n",
    "\n",
    "</p>\n",
    "</details> "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Change index**"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We can change the index in a `DataFrame`. However, remember that the index must be unique to every observation!"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "titanic.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "titanic['PassengerId'].nunique()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We change the index of a `DataFrame` by assigning a sequence (e.g. a column) with new index values to the `index` attribute of the `DataFrame`."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "titanic.index = titanic['PassengerId']\n",
    "\n",
    "titanic.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "titanic.drop('PassengerId', axis = 1, inplace = True)\n",
    "\n",
    "titanic.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<div class=\"alert alert-info\">\n",
    "<h3> Your turn</h3>\n",
    "    <p> Change the index in <code>temp_df</code> to the day of week, i.e. 'mon', 'tue', 'wed',..., 'sun'. \n",
    "</div>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Solution**\n",
    "\n",
    "<details>\n",
    "    \n",
    "<summary> Click to expand!</summary>\n",
    "<p> \n",
    "\n",
    "```c#\n",
    "# Alternative 1:\n",
    "# assign list of new index values to index\n",
    "    \n",
    "temp_df.index = ['mon', 'tue', 'wed', 'thur', 'fri', 'sat', 'sun']\n",
    "    \n",
    "    \n",
    "# Alternative 2:\n",
    "# add new column with the day of week and then set index equal to new column\n",
    "\n",
    "temp_df['day'] = ['mon', 'tue', 'wed', 'thur', 'fri', 'sat', 'sun']\n",
    "    \n",
    "temp_df.index = temp_df['day']\n",
    "\n",
    "```\n",
    "\n",
    "</p>\n",
    "</details> "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We can reset the index by using the `reset_index` function. We set the parameter `inplace` equal to `True` in order to reset the index in the original `DataFrame`."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "titanic.reset_index(inplace = True)\n",
    "\n",
    "titanic.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Notice that `reset_index` is returning the old index as a column to the `DataFrame`. We can avoid this by setting `drop = True`."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<div class=\"alert alert-info\">\n",
    "<h3> Your turn</h3>\n",
    "    <p> Reset the index in <code>temp_df</code>.\n",
    "        \n",
    "</div>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Solution**\n",
    "\n",
    "<details>\n",
    "    \n",
    "<summary> Click to expand!</summary>\n",
    "<p> \n",
    "\n",
    "```c#\n",
    "# notice that if the dataframe already contains a column identical to the index, i.e. alternative 2 in previous exercise, \n",
    "# then you must set 'drop = True' in order to avoid duplication of columns\n",
    "# try with both 'drop = False' and 'drop = True' and see what happens!\n",
    "    \n",
    "temp_df.reset_index(inplace = True, drop = True)\n",
    "\n",
    "\n",
    "```\n",
    "\n",
    "</p>\n",
    "</details> "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Filtering rows\n",
    "\n",
    "We can select a subset of the rows and columns in a `DataFrame` based on one or several conditions using *relational operators*."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df['Score'] > 80"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We can store the `Series` of boolean values in a variable."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "above_80 = df['Score'] > 80\n",
    "\n",
    "above_80"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We can use this `Series` of boolean values to filter the `DataFrame` by placing the `Series` inside the index operator `[]`. \n",
    "\n",
    "This will select only the rows for which the value is `True`."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df[above_80]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Notice that we can place the condition that we want to filter on directly inside the index operator `[]`."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df[df['Score'] > 80]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Remember that the relational operators are `<`, `>`, `<=`, `>=`, `==`, and `!=`."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df[df['City'] != 'Trondheim']"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "As before, we can save the **subset** of the original `DataFrame` in a new variable. \n",
    "\n",
    "However, remember that we must append `copy` at the end of the subset in order to create a new `DataFrame`."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_above_80 = df[df['Score'] > 80].copy()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_above_80"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Let us filter the rows in `titanic` on the sex of the passengers."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "males = titanic[titanic['Sex'] == 'male'].copy()\n",
    "\n",
    "males.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "females = titanic[titanic['Sex'] == 'female'].copy()\n",
    "\n",
    "females.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "len(males)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "len(females)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We can double check our numbers using `value_counts`."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "titanic['Sex'].value_counts()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Notice that we can also filter a `DataFrame` on multiple conditions. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "cond1 = df['Score'] > 80\n",
    "cond2 = df['City'] != 'Trondheim'"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "However, each condition must be surrounded by parentheses `()`, and we have to use the operator `|` for 'or' and the operator `&` for 'and'."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df[(cond1) & (cond2)]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df[(cond1) | (cond2)]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<div class=\"alert alert-info\">\n",
    "<h3> Your turn</h3>\n",
    "    <p> Display the passengers in <code>titanic</code> that were male AND older than 70 years.\n",
    "        \n",
    "</div>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Solution**\n",
    "\n",
    "<details>\n",
    "    \n",
    "<summary> Click to expand!</summary>\n",
    "<p> \n",
    "\n",
    "```c#\n",
    "titanic[(titanic['Sex'] == 'male') & (titanic['Age'] > 70)]\n",
    "```\n",
    "\n",
    "</p>\n",
    "</details> "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Plotting**\n",
    "\n",
    "Let us create a histogram of the age of the female passengers seperately for those that survived and those that did not."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We must first filter the `titanic` data on the sex of the passenger and on whether the passenger survived or not."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# females that survived\n",
    "females_1 = titanic[(titanic['Sex'] == 'female') & (titanic['Survived'] == 1)].copy()\n",
    "\n",
    "# females that did not survive\n",
    "females_0 = titanic[(titanic['Sex'] == 'female') & (titanic['Survived'] == 0)].copy()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We can then use `hist` from `matplotlib` to show a histogram of the age."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Side note**: Let us change the style of our plots!"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# see all styles available\n",
    "plt.style.available"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# set style for the rest of the program\n",
    "plt.style.use('ggplot')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "fig, ax = plt.subplots()\n",
    "\n",
    "ax.hist(females_1['Age'],\n",
    "        bins = 30, \n",
    "        alpha = 0.5,\n",
    "        label = 'Survived')\n",
    "\n",
    "ax.hist(females_0['Age'],\n",
    "        bins = 30, \n",
    "        alpha = 0.5,\n",
    "        label = 'Not survived')\n",
    "\n",
    "ax.set_title('Female passengers')\n",
    "\n",
    "ax.legend()\n",
    "\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<div class=\"alert alert-info\">\n",
    "<h3> Your turn</h3>\n",
    "    <p> Create a figure with two subplots:\n",
    "        \n",
    "- In the first subplot, show a histogram of the age of female passengers seperately for those that survived and for those that did not.\n",
    "        \n",
    "        \n",
    "- In the second subplot, show a histogram of the age of the male passengers seperately for those that survived and for those that did not.\n",
    "               \n",
    "</div>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Solution**\n",
    "\n",
    "<details>\n",
    "    \n",
    "<summary> Click to expand!</summary>\n",
    "<p> \n",
    "\n",
    "```c#\n",
    "# new dfs with males that survived and males that did not survive (remember to use copy command!)\n",
    "males_1 = titanic[(titanic['Sex'] == 'male') & (titanic['Survived'] == 1)].copy()\n",
    "males_0 = titanic[(titanic['Sex'] == 'male') & (titanic['Survived'] == 0)].copy()\n",
    "\n",
    "fig, ax = plt.subplots(nrows = 1, \n",
    "                       ncols = 2, \n",
    "                       figsize = (10, 3), \n",
    "                       sharey = True) # set same y-range in both subplots\n",
    "\n",
    "# subplot 1 (females):\n",
    "    \n",
    "ax[0].hist(females_1['Age'],\n",
    "           bins = 30, \n",
    "           alpha = 0.5,\n",
    "           label = 'Survived')\n",
    "    \n",
    "ax[0].hist(females_0['Age'],\n",
    "           bins = 30, \n",
    "           alpha = 0.5,\n",
    "           label = 'Not survived')\n",
    "\n",
    "# subplot 2 (males):\n",
    "    \n",
    "ax[1].hist(males_1['Age'],\n",
    "           bins = 30, \n",
    "           alpha = 0.5,\n",
    "           label = 'Survived')\n",
    "    \n",
    "ax[1].hist(males_0['Age'],\n",
    "           bins = 30, \n",
    "           alpha = 0.5,\n",
    "           label = 'Not survived')\n",
    "\n",
    "# set titles and add legends\n",
    "ax[0].set_title('Female passengers')\n",
    "ax[1].set_title('Male passengers')\n",
    "ax[0].legend()\n",
    "ax[1].legend()\n",
    "\n",
    "plt.show()\n",
    "    \n",
    "```\n",
    "\n",
    "</p>\n",
    "</details> "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Groupby\n",
    "\n",
    "The `groupby` function groups together rows based on the columns and returns an object\n",
    "that contains information about the groups.\n",
    "\n",
    "This is very helpful in data analysis as it helps us summarize information about different groups in our data."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df['Pass'] = ['yes', 'no', 'yes', 'yes']\n",
    "\n",
    "df"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "`groupby` returns an object that we can perform operations on."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "pass_group = df.groupby('Pass')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "pass_group"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We can retrive summary statistics for the groups using e.g. `mean`, `sum`, `count`, `max`."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "pass_group.mean()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "pass_group['Score'].mean()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We can use `value_counts` to count the number of passengers in our Titanic data that survived."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "titanic['Survived'].value_counts()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "But what if we want to know the number of passengers that survived in 1st, 2nd and 3rd class?\n",
    "\n",
    "Then we first have to group the data together on the column `Pclass`."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "titanic.groupby('Pclass')['Survived'].value_counts()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We can use `mean` to calculate the average age of passengers traveling 1st, 2nd and 3rd class."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "titanic.groupby('Pclass')['Age'].mean()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "But what if we want to know the average age for men and women traveling 1st, 2nd and 3rd class?\n",
    "\n",
    "We can group the data by *multiple* columns by passing a list of column names to `groupby`."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "titanic.groupby(['Pclass', 'Sex'])['Age'].mean()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<div class=\"alert alert-info\">\n",
    "<h3> Your turn</h3>\n",
    "    <p> What was the most expensive ticket, i.e. highest fare, in 1st, 2nd and 3rd class?\n",
    "        \n",
    "</div>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Solution**\n",
    "\n",
    "<details>\n",
    "    \n",
    "<summary> Click to expand!</summary>\n",
    "<p> \n",
    "\n",
    "```c#\n",
    "titanic.groupby('Pclass')['Fare'].max()   \n",
    "```\n",
    "\n",
    "</p>\n",
    "</details> "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Plotting**\n",
    "\n",
    "Let us plot the share of survivors by 1st, 2nd and 3rd class.\n",
    "\n",
    "We must first calculate the share of survivors in each class."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "pclass = titanic.groupby('Pclass')['Survived'].mean()\n",
    "\n",
    "pclass"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We can then update the index of the `Series`."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "pclass.index = ['1st class', '2nd class', '3rd class']\n",
    "\n",
    "pclass"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We can then use `bar` from `matplotlib` to show the share of survivors by `pclass` in a bar plot."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "fig, ax = plt.subplots()\n",
    "\n",
    "ax.bar(pclass.index,\n",
    "       pclass)\n",
    "\n",
    "ax.set_ylabel('Share of survivors')\n",
    "\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<div class=\"alert alert-info\">\n",
    "<h3> Your turn</h3>\n",
    "    <p> Use <code>mpg_df</code> and create a bar plot of average <code>mpg</code> by the <code>origin</code> of the car. \n",
    "        \n",
    "</div>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Solution**\n",
    "\n",
    "<details>\n",
    "    \n",
    "<summary> Click to expand!</summary>\n",
    "<p> \n",
    "\n",
    "```c#\n",
    "# df with average mpg by origin (do not need to use copy because we are not subsetting an existing df)\n",
    "origin = mpg_df.groupby('origin')['mpg'].mean()\n",
    "    \n",
    "fig, ax = plt.subplots()\n",
    "\n",
    "ax.bar(origin.index,\n",
    "       origin)\n",
    "\n",
    "ax.set_ylabel('Average mpg')\n",
    "\n",
    "plt.show() \n",
    "```\n",
    "\n",
    "</p>\n",
    "</details> "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Combining data\n",
    "\n",
    "`pandas` offers several different ways of combining `DataFrame`s. The two most useful functions for combining data are `concat` and `merge`."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Concat**\n",
    "\n",
    "We can use `concat` to stack `DataFrame`s that share the same columns, but have different observations. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df # original df with grades"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# create dict\n",
    "grade_dict2 = {'Name'  : ['Nico', 'Maria', 'Mario', 'Janne'],\n",
    "               'Score' : [67, 48, 92, 71], \n",
    "               'Age'   : [18, 24, 21, 20], \n",
    "               'City'  : ['Bergen', 'Oslo', 'Oslo', 'Trondheim'],\n",
    "               'Pass'  : ['yes', 'no', 'yes', 'yes']}\n",
    "\n",
    "# convert dict to df\n",
    "df2 = pd.DataFrame(grade_dict2)\n",
    "\n",
    "df2 # new df with additional grades"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "As a default, `concat` stacks a list of `DataFrame`s on top of each other. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "pd.concat([df, df2])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "But what if the `DataFrame`s do not have the exact same columns?\n",
    "\n",
    "Let us drop `Pass` from `df2`."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df2.drop('Pass', axis = 1, inplace = True)\n",
    "\n",
    "df2"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We can still `concat` the `DataFrame`s. `concat` will simply fill the cells with missing data with `NaN`."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# store in new variable\n",
    "df3 = pd.concat([df, df2]) \n",
    "\n",
    "df3"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "However, notice that the index is now no longer unique to each observation (row). \n",
    "\n",
    "This can be fixed using the `reset_index` function. `inplace = True` will reset the index in the original `DataFrame`, while `drop = True` will avoid that the old index is added as a new column."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df3.reset_index(inplace = True, drop = True)\n",
    "\n",
    "df3"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<div class=\"alert alert-info\">\n",
    "<h3> Your turn</h3>\n",
    "    <p> Use <code>concat</code> to combine the observations in <code>females</code> and <code>males</code> that we created earlier back together. Check that you have 891 observations in the new <code>DataFrame</code>. \n",
    " \n",
    "</div>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Solution**\n",
    "\n",
    "<details>\n",
    "    \n",
    "<summary> Click to expand!</summary>\n",
    "<p> \n",
    "\n",
    "```c#\n",
    "titanic_concat = pd.concat([females, males], axis = 0)\n",
    "\n",
    "print(len(titanic_concat))\n",
    "```\n",
    "\n",
    "</p>\n",
    "</details> "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Merge**\n",
    "\n",
    "We can use `merge` to combine `DataFrame`s that share the same observations, but have different columns."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df1 = pd.DataFrame({'Name': ['Ole', 'Jenny', 'Chang', 'Jonas', 'Mario'],\n",
    "                    'Score1' : [65.0, 58.0, 79.0, 95.0, 92.0]})\n",
    "\n",
    "df1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df2 = pd.DataFrame({'Name': ['Ole', 'Chang', 'Jonas', 'Mario', 'Nico', 'Maria'],\n",
    "                    'Score2' : [70.0, 77.0, 92.0, 92.0, 72.0, 68.0]})\n",
    "\n",
    "df2"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The two `DataFrame`s share the column `Name`, and we can merge the data on `Name` using `merge`.\n",
    "\n",
    "We must specify that we want to merge on `Name`."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df1.merge(df2, on = 'Name')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "By default, `merge` will combine only those observations found in both `DataFrame`s, i.e. an inner join."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "If we want to keep all of the observations in the left `DataFrame`, we must set `how = 'left'`."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df1.merge(df2, on = 'Name', how = 'left')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Or if we want to keep all of the observations in the right `DataFrame`, we must set `how = 'right'`."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df1.merge(df2, on = 'Name', how = 'right')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Or if we want to keep all observations in both `DataFrame`s, we must set `how = 'outer'`."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df1.merge(df2, on = 'Name', how = 'outer')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Notice that when the `DataFrame`s have more than one common variable, we must merge on all of the common variables."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df1 = pd.DataFrame({'Name'       : ['Ole', 'Jenny', 'Chang', 'Jonas', 'Mario'],\n",
    "                    'Student_no' : ['s1001', 's1002', 's1003', 's1004', 's1005'],\n",
    "                    'Score1'     : [65.0, 58.0, 79.0, 95.0, 92.0]})\n",
    "\n",
    "df1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df2 = pd.DataFrame({'Name'       : ['Ole', 'Chang', 'Jonas', 'Mario', 'Nico', 'Maria'],\n",
    "                    'Student_no' : ['s1001', 's1003', 's1004', 's1005', 's1006', 's1007'],\n",
    "                    'Score2'     : [70.0, 77.0, 92.0, 92.0, 72.0, 68.0]})\n",
    "\n",
    "df2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df1.merge(df2, on = 'Name', how = 'outer')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We can merge on multiple variables by passing a list of variables to `on` in `merge`."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_merge = df1.merge(df2, on = ['Name', 'Student_no'], how = 'outer')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_merge"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<div class=\"alert alert-info\">\n",
    "<h3> Your turn</h3>\n",
    "    <p> The file <code>titanic_fam.csv</code> contains additional information for each passenger in our <code>titanic</code> data:\n",
    "        \n",
    "- SibSp: number of siblings and spouse on board\n",
    "- Parch: number of parents and children on board\n",
    "        \n",
    "Import the file, and merge it with <code>titanic</code>.\n",
    "        \n",
    "</div>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Solution**\n",
    "\n",
    "<details>\n",
    "    \n",
    "<summary> Click to expand!</summary>\n",
    "<p> \n",
    "\n",
    "```c#\n",
    "# import additional data\n",
    "titanic_fam = pd.read_csv('data/titanic_fam.csv')\n",
    "\n",
    "# merge with original data (and overwrite the old variable name)\n",
    "titanic = titanic.merge(titanic_fam, on = ['PassengerId', 'Name'])\n",
    "```\n",
    "\n",
    "</p>\n",
    "</details> "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Reshape\n",
    "\n",
    "Usually in data analysis we want tidy data:\n",
    "1. Each column is a variable\n",
    "2. Each row is an observation\n",
    "\n",
    "This is also known as *long* data. \n",
    "\n",
    "<img src=\"images/tidy.png\" width = \"60%\" align=\"left\"/>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Let us create a `DataFrame` that contains (made-up) closing prices for Google and Apple during a week. \n",
    "\n",
    "Since there are two columns constaining the closing price, this is not *long* data. Instead it is *wide*. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "data = {'Day'    : ['MON', 'TUE', 'WED', 'THU', 'FRI'], \n",
    "        'Google' : [1129, 1132, 1134, 1152, 1152], \n",
    "        'Apple'  : [191, 192, 190, 190, 188]}\n",
    "\n",
    "wide_df = pd.DataFrame(data)\n",
    "\n",
    "wide_df"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "`melt` reshapes a `DataFrame` from wide to long. In order to use `melt`, we must pass a column label to the `id_vars` parameter. This is the column that we want to leave \"untouched\"."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "wide_df.melt(id_vars = 'Day')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "In addition, we can pass arguments to the `var_name` and `value_name` parameters in order to specify the new column names."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "long_df = wide_df.melt(id_vars = 'Day', var_name = 'Company', value_name = 'Closing Price')\n",
    "\n",
    "long_df"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<div class=\"alert alert-info\">\n",
    "<h3> Your turn</h3>\n",
    "    <p> Reshaping data from long to wide is known as pivoting. To pivot a <code>DataFrame</code>, <code>pandas</code> has a function called <code>pivot</code>.\n",
    "        \n",
    "See if you can find out how to pivot <code>long_df</code> back to <code>wide_df</code>.\n",
    "        \n",
    "</div>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Solution**\n",
    "\n",
    "<details>\n",
    "    \n",
    "<summary> Click to expand!</summary>\n",
    "<p> \n",
    "\n",
    "```c#\n",
    "# pivot from long to wide\n",
    "wide_df = long_df.pivot(index = 'Day', columns = 'Company', values = 'Closing Price').reset_index()\n",
    "\n",
    "# remove index name (not necessary, just to make it look nicer)\n",
    "wide_df.rename_axis(None, axis = 1, inplace = True)\n",
    "\n",
    "```\n",
    "\n",
    "</p>\n",
    "</details> "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Mandatory exercise part 1\n",
    "\n",
    "In this exercise you are asked to work with two different datasets:\n",
    "- `closing_prices.csv` contains the daily closing price in 2020 for ten different stocks.\n",
    "- `EXR.xlsx` contains that daily exchange rate from USD to NOK in 2020 retrieved from Norges Bank.\n",
    "\n",
    "You are asked to:\n",
    "\n",
    "1. Import and clean the files\n",
    "2. Merge the files and convert the closing price from USD to NOK\n",
    "3. Create and save a graph that shows the daily closing price in NOK for Apple"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
